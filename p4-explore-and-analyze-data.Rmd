---
title: "Exploratory Data Analysis of Uber Pickup Data"
author: "Courtney Ferguson Lee"
date: "5/9/2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



```{r echo = FALSE, message = FALSE, warning = FALSE, packages}
library(ggplot2)
library(tidyr)
library(dplyr)
library(GGally)
library(scales)
library(memisc)
library(readr)
library(gridExtra)
library(RColorBrewer)
library(bitops)
library(RCurl)
#devtools::install_github("dkahle/ggmap")
library(ggmap)
#library(maptools)
#library(devtools)
#install_github("quantide/mapIT")
library(lubridate)
#library(scales)
```



```{r echo=FALSE, Load_the_Data}

# Read csv's and load taxi lookup data
setwd('/Users/courtneyfergusonlee/Downloads/p4-master')
uber <- read.csv('uber-raw-data-janjune-15.csv')
taxi_lookup <- read.csv('taxi-zone-lookup.csv', stringsAsFactors = F)
# Edit Zones for more accurate location results
taxi_lookup[17, 3] <- 'Bedford-Stuyvesant'
taxi_lookup[23, 3] <- 'Bloomfield'
taxi_lookup[81, 3] <- 'Eastchester, Bronx'

# Get latitude and longitude info for location data (Long Process)
citystate = 'new york city new york'
taxi_lookup <- mutate(taxi_lookup, 
       lat = geocode(paste(Zone, citystate, sep = ', '), output = 'latlon')$lat,
       lon = geocode(paste(Zone, citystate, sep = ', '), output = 'latlon')$lon)

# Check for missing latitude or longitude data
taxi_lookup.lat_na <- subset(taxi_lookup, is.na(lat))
taxi_lookup.lon_na <- subset(taxi_lookup, is.na(lon))
taxi_lookup.lat_na
taxi_lookup.lon_na

# If there's missing data, need to rename variables and replace values as nec.
names(taxi_lookup.lat_na) <- c("LocationID", 
                           "Borough",    
                           "Zone",       
                           "latitude",
                           "longitude")
names(taxi_lookup.lon_na) <- c("LocationID", 
                           "Borough",    
                           "Zone",       
                           "latitude",
                           "longitude")

# Lookup missing values in bulk, check for warnings
taxi_lookup.lat_na <- mutate(taxi_lookup.lat_na, 
       latitude = geocode(paste(Zone, citystate, sep = ', '), 
                          output = 'latlon')$lat)
taxi_lookup.lon_na <- mutate(taxi_lookup.lon_na, 
       longitude = geocode(paste(Zone, citystate, sep = ', '), 
                          output = 'latlon')$lon)

# Replace missing values CAREFULLY (Lookup is a long process)
taxi_lookup[taxi_lookup.lat_na$LocationID, 4] <- taxi_lookup.lat_na$latitude
taxi_lookup[taxi_lookup.lon_na$LocationID, 5] <- taxi_lookup.lon_na$longitude

```



```{r echo=FALSE, Sample_the_Data}

# Grab samples to lighten system load and run tests
set.seed(420)
uber_sample <- uber[sample(1:length(uber$locationID), 100000), ]

# Create Zone, Borough, lat, lon, hour, day, month and date variables
uber_sample <- uber_sample %>%
  inner_join(taxi_lookup, 
             by = c('locationID' = 'LocationID')) %>%
  mutate(hour = hour(Pickup_date),
         day = wday(Pickup_date, label = T, abbr = F),
         month = month(Pickup_date, label = T, abbr = F),
         date = day(Pickup_date))

# Known locations needeed for map
uber_sample_known <- uber_sample %>%
  filter(Borough != 'Unknown' & Borough != 'EWR') # EWR is NJ

```



```{r echo=FALSE, Format_the_Data}

# Create Zone, Borough, lat, lon, hour, day, month and date variables
uber <- uber %>%
  inner_join(taxi_lookup, 
             by = c('locationID' = 'LocationID')) %>%
  mutate(hour = hour(Pickup_date),
         day = wday(Pickup_date, label = T, abbr = F),
         month = month(Pickup_date, label = T, abbr = F),
         date = day(Pickup_date))

# Create Zone, Borough, lat, lon, hour, day, month and date variables
uber_known <- uber %>%
  filter(Borough != 'Unknown' & Borough != 'EWR') # EWR is NJ


# Create month tables for quicker execution
uber_jan <- uber %>%
  filter(month == 'January')
uber_feb <- uber %>%
  filter(month == 'February')
uber_mar <- uber %>%
  filter(month == 'March')
uber_apr <- uber %>%
  filter(month == 'April')
uber_may <- uber %>%
  filter(month == 'May')
uber_jun <- uber %>%
  filter(month == 'June')

# Create Saturday tables to make comparisons
saturday_rides <- uber%>%
  filter(day == 'Saturday') %>%
  group_by(month, date, day, hour) %>%
  summarise(rides = n()) %>%
  ungroup()

saturday_ave <- saturday_rides %>%
  group_by(day, hour) %>%
  summarise(ave_rides = mean(rides))

# Create individual date tables for comparisons
may_16.by_hour <- uber_may %>%
  filter(date == 16) %>%
  group_by(month, date, day, hour) %>%
  summarise(rides = n()) %>%
  ungroup() %>%
  inner_join(saturday_ave)

may_23.by_hour <- uber_may %>%
  filter(date == 23) %>%
  group_by(month, date, day, hour) %>%
  summarise(rides = n()) %>%
  ungroup() %>%
  inner_join(saturday_ave)

june_27.by_hour <- uber_jun %>%
  filter(date == 27) %>%
  group_by(month, date, day, hour) %>%
  summarise(rides = n()) %>%
  ungroup() %>%
  inner_join(saturday_ave)

# Bin by quarter hour, half hour, hour and day, turning rides into a variable
uber.by_quarter_hour <- uber %>%
  mutate(minute = minute(Pickup_date),
         quarter_hour = floor(minute/15) * 15,
         hour_plus_quarter = hour + quarter_hour/60) %>%
  group_by(month, 
           date, 
           day, 
           hour,
           hour_plus_quarter) %>%
  summarise(rides = n()) %>%
  ungroup()

uber.by_half_hour <- uber %>%
  mutate(minute = minute(Pickup_date),
         half_hour = floor(minute/30) * 30,
         hour_plus_half = hour + half_hour/60) %>%
  group_by(month, 
           date, 
           day, 
           hour,
           hour_plus_half) %>%
  summarise(rides = n()) %>%
  ungroup()

uber.by_hour <- uber %>%
  group_by(month, 
           date, 
           day, 
           hour) %>%
  summarise(rides = n()) %>%
  ungroup()

uber.by_day <- uber %>%
  group_by(month, 
           date, 
           day) %>%
  summarise(rides = n()) %>%
  ungroup()


# Bin by location for map scatter plot and location boxplot
uber_known.by_loc <- uber_known %>%
  group_by(Zone) %>%
  summarise(rides = n()) %>%
  inner_join(taxi_lookup) %>%
  ungroup()

# Bin by hour and location
uber_known.by_hour_borough <- uber_known %>%
  group_by(month,
           date,
           day,
           hour,
           Borough) %>%
  summarise(rides = n()) %>%
  ungroup()

```


# Univariate Plots Section

## Hourly Pickups

```{r echo=FALSE, Hourly_Pickups}
ggplot(uber,
       aes(x = hour)) +
  geom_freqpoly(binwidth = 1,
                color = I('Blue')) +
  scale_x_continuous(breaks = 0:23) +
  ggtitle('Pickups per Hour') +
  xlab('Time') +
  ylab('Number of Pickups') +
  ggsave('graphs/hourly_pickups_freqpoly.png')
```

The graph above shows the total number of pickups per hour.  There are 3 notable
spikes at midnight (0), 8am and 7pm.  The largest by far is the third peak.
It's also interesting that there is a small bump around noon for lunch.


## Daily Pickups

```{r echo=FALSE, Daily_Pickups}
ggplot(uber.by_day,
       aes(x = day,
           y = rides)) +
  geom_boxplot(aes(color = day)) +
  scale_color_brewer(type = 'qual',
                     palette = 2) +
  scale_y_continuous(labels = comma,
                     breaks = seq(0, 150000, 25000)) +
  ggtitle('Pickups per Day') +
  labs(color = 'Day') +
  xlab('Day') +
  ylab('Number of Pickups') +
  ggsave('graphs/pickups_per_day_boxplot.png')
```

Pickups per day followed an expected trend, with demand rising Monday - Friday, 
then peaking on the weekend.  It's also interesting to note the differences in
ranges for each day.  I expected Friday's variation to be larger than any other
day but it was tighter and consistently larger instead.

## Monthly Pickups

```{r echo=FALSE, Monthly_Pickups}
ggplot(uber,
       aes(x = month)) +
  geom_bar(aes(fill = month)) +
  scale_fill_brewer(type = 'seq',
                     palette = 1,
                    direction = 1) +
  scale_y_continuous(labels = comma) +
  ggtitle('Pickups per Month') +
  labs(fill = 'Month') +
  ylab('Number of Pickups') +
  xlab('Month') +
  ggsave('graphs/pickups_per_month_barplot.png')
```

Demand over this 6-month span rose from a little under 2,000,000 rides in
January to nearly 3 million in June.  This may have been due to an increase in popularity or warmer weather or both, but more data is needed to make 
generalizations on monthly patterns.

## Pickups by Location

```{r echo=FALSE, Location_Pickups}
ggplot(uber_known.by_loc,
       aes(x = Borough,
           y = rides)) +
  geom_boxplot(aes(color = Borough)) +
  scale_y_log10(labels = comma,
                breaks = c(100, 1000, 10000, 100000, 500000)) +
  scale_color_brewer(type = 'qual',
                     palette = 6) +
  ggtitle('Pickups by Location') +
  ylab('Number of Pickups') +
  ggsave('graphs/pickups_by_location_boxplot.png', 
         width = 12, 
         height = 8, 
         units = 'in')

```

The largest variation was in the location data.  Staten Island had very few
pickups in each zone, with most falling in the low 100's.  Manhattan by contrast
had the most pickups with some zones nearing 500,000.  An Uber driver would be
wise to spend most of his time in that Borough.

# Univariate Analysis

## 

### What is the structure of your dataset?

The Uber dataset consisted of 14 million observations of pickup data spread
across 12 variables.  The data was submitted by the Taxi & Limousine Commission
(TLC) through a Freedom of Information Law request submitted on June 22, 2015.
Each observation represents a single pickup.

Originally there were only 4 variables (Dispatch base number, pickup date, 
affiliated base number, and location ID), but I joined that with taxi lookup
data to get Zone and Borough names for each location ID.  I also wanted to map 
each location to a set of coordinates so I used Google's API to get the latitude
and longitude for each zone.  The Google API limits users to 2500 queries
during each 24 hour period so I had to be strategic when joining the lookup
data to the ridership data.

### What is/are the main feature(s) of interest in your dataset?

I was most interested in how ridership varied over time and location.  I wanted 
to know how it changed by hour, week, day and month.  I also wanted to
know what the most popular Boroughs and Zones were.

As a former Uber driver, I was very interested in how closely rider behavior 
aligned with my expectations.  It is important to know the market in order
to turn a profit.  Being in the right place at the right time can be the
difference between a $2000 week and a $200 one.  If more drivers were more aware
of the cyclical patterns in their area they would be better equipped to maximize
their time and profit.


### What other features in the dataset do you think will help support your \
investigation into your feature(s) of interest?

### Did you create any new variables from existing variables in the dataset?

I parsed the month, date, day, and hour from each pickup timestamp using 
lubridate to get a more granular analysis of patterns over time.  I also binned
the pickup data by location and time to create some of the graphs.  I came
across a dilema when choosing whether to include some of the taxi lookup data
because the location data was missing.  It was a small subset (about 6000
observations) but I did not want to throw away the data.  Instead, I kept all
observations for the time period analyses and excluded them when making the
scatterplot map and boxplot for the location analyses.

Since the dataset was large, I ran most tests on a sample of 100,000 randomly
selected observations before making the final plots on the population.  This
saved a lot of time since some plots took a couple minutes (each) to run.


### Of the features you investigated, were there any unusual distributions? \
The most unusual distributions came from the location data.  Some boroughs only
had a few hundred pickups while others were in the 10's of thousands and even
hundreds of thousands.  This was unusual because as I saw later, these patterns
did not change over the course of the week.  Manhattan was still the busiest
place on the weekend and during the week.  

Even more unusual was the fact that Manhattan (pop 1.6 million) is not the most populated Borough in New York.  Brooklyn (2.6 million) and Queens (2.3 million) 
have considerably larger populations.  By contrast, the population density of
Manhattan is twice that of Brooklyn and triple that of Queens.  This could be
worth investigating for Uber as they expand into more markets.  It would be
interesting to look at ridership data for other cities to look for correlations.

Did you perform any operations on the data to tidy, adjust, or change the form \
of the data? If so, why did you do this?

I used the dplyr and tidyr packages to reshape the data.  This helped parse the
time data to get month, date, day and hour variables.  It also helped when I
needed to bin and summarise observations to get the number of rides by time
period and location.  One day I hope to shake Hadley Wickham's hand for what
he has done for the data science community.  He is truly a prolific developer
in the R community and I feel a certain level of comfort when I see his name
in a package's documentation.

# Bivariate Plots

## Hourly Pickups

```{r echo=FALSE, Hourly_by_Day}
ggplot(uber,
       aes(x = hour)) +
  geom_histogram(binwidth = 1,
                aes(color = day)) +
  scale_x_continuous(breaks = seq(0,24,6)) +
  scale_color_brewer(type = 'qual', palette = 1) +
  ggtitle('Hourly Pickups by Day') +
  guides(color = F) +
  xlab('Time') +
  ylab('Number of Pickups') +
  facet_wrap(~ day) +
  ggsave('graphs/hourly_pickups_by_day_histogram.png', 
         width = 12, 
         height = 8, 
         units = 'in')
```

## Monthly Pickups Colored by Day

```{r echo=FALSE, Monthly_Pickups_Colored_by_Day}
# Number of pickups over time colored by day
ggplot(uber,
       aes(x = date)) +
  geom_histogram(binwidth = 1,
                aes(fill = day)) +
  scale_x_continuous(breaks = seq(7, 28, 7)) +
  scale_y_continuous(labels = comma) +
  scale_fill_brewer(type = 'seq', palette = 1) +
  ggtitle('Monthly Pickups Colored by Day') +
  labs(fill = 'Day') +
  xlab('Date') +
  ylab('Number of Pickups') +
  facet_wrap(~ month) +
  ggsave('graphs/monthly_pickups_histogram.png', 
         width = 12, 
         height = 8, 
         units = 'in')
```

## May and June In-Depth

```{r}
# Create histogram of pickups, faceted by date
# May
ggplot(uber_may,
       aes(x = hour)) +
  geom_freqpoly(aes(color = day),
                binwidth = 1) +
  scale_x_continuous(breaks = seq(0, 24, 6)) +
  scale_color_brewer(type = 'qual', 
                     palette = 2) +
  ggtitle('May Pickups') +
  labs(color = 'Day') +
  xlab('Time') +
  ylab('Number of Pickups') +
  facet_wrap(~ date, ncol = 7) +
  ggsave('graphs/may_pickups.png', 
         width = 12, 
         height = 8, 
         units = 'in')


# June
ggplot(uber_jun,
       aes(x = hour)) +
  geom_freqpoly(aes(color = day),
                binwidth = 1) +
  scale_x_continuous(breaks = seq(0, 24, 6)) +
  scale_color_brewer(type = 'qual', 
                     palette = 2) +
  ggtitle('June Pickups') +
  labs(color = 'Day') +
  xlab('Time') +
  ylab('Number of Pickups') +
  facet_wrap(~ date, ncol = 7) +
  ggsave('graphs/june_pickups.png', 
         width = 12, 
         height = 8, 
         units = 'in')

# Look at percent change for May 16, May 24 and June 25 vs typical Saturdays
# x-axis: hours
# y-axis: percent change from baseline
p1 <- ggplot(may_16.by_hour,
       aes(x = hour,
           y = rides / ave_rides)) +
  geom_line(aes(color = I('blue'))) +
  geom_hline(linetype = 2, alpha = .3, yintercept = 1) +
  scale_x_continuous(breaks = seq(0,24,1)) +
  scale_y_continuous(labels = scales::percent,
                     limits = c(.6,1.8),
                     breaks = seq(.6,1.8,.2)) +
  ggtitle('Saturday, May 16 Pickups') +
  ylab('Pickups (% Versus Ave Saturday)') +
  xlab('Time')

p2 <- ggplot(may_23.by_hour,
       aes(x = hour,
           y = rides / ave_rides)) +
  geom_line(aes(color = I('purple'))) +
  geom_hline(linetype = 2, alpha = .3, yintercept = 1) +
  scale_x_continuous(breaks = seq(0,24,1)) +
  scale_y_continuous(labels = scales::percent,
                     limits = c(.6,1.8),
                     breaks = seq(.6,1.8,.2)) +
  ggtitle('Saturday, May 23 Pickups') +
  ylab('Pickups (% Versus Ave Saturday)') +
  xlab('Time')

p3 <- ggplot(june_27.by_hour,
       aes(x = hour,
           y = rides / ave_rides)) +
  geom_line(aes(color = I('red'))) +
  geom_hline(linetype = 2, alpha = .3, yintercept = 1) +
  scale_x_continuous(breaks = seq(0,24,1)) +
  scale_y_continuous(labels = scales::percent,
                     limits = c(.6,1.8),
                     breaks = seq(.6,1.8,.2)) +
  ggtitle('Saturday, June 27 Pickups') +
  ylab('Pickups (% Versus Ave Saturday)') +
  xlab('Time')

grid.arrange(p1, p2, p3, ncol = 1)

g <- arrangeGrob(p1, p2, p3, ncol = 1) #generates g
 ggsave(file="graphs/may16_may23_jun27_percent_change.png", 
        g,
        width = 12, 
         height = 8, 
         units = 'in')
```

# Multivariate Plots Section

## Map Scatter Plot

```{r echo=FALSE Map_Scatter_Plot}
# Map Scatterplot of New York Pickups

lon_left <- min(taxi_lookup$lon)
lon_right <- max(taxi_lookup$lon)
lat_bottom <- min(taxi_lookup$lat)
lat_top <- max(taxi_lookup$lat)

subset(taxi_lookup,lat > 40.9)
subset(taxi_lookup, lat > 40.8 & lon < -74.1)

nyc <- get_map(location = c(lon_left, 
                            lat_bottom,
                            lon_right,
                            lat_top), 
               source = 'stamen')

nycMap <- ggmap(nyc,
                    extent = "panel")

nycMap +
  geom_point(aes(x = lon,
                 y = lat,
                 size = rides,
                 color = rides,
                 alpha = .01),
             #alpha = .01,
             data = uber_known.by_loc) +
  scale_color_gradient2(low = 'yellow',
                       high = 'red',
                       mid = 'yellow',
                       labels = comma,
                       guide = guide_colorbar(barheight = 20,
                                              title = 'Pickups')) +
  ggtitle('Uber Pickups Scatterplot Map') +
  scale_size(guide = 'none') +
  guides(alpha = F) +
  ggsave('graphs/scatterplot_map.png')

```

## Heatmap by month and date

```{r}
ggplot(aes(y = date, 
           x = month),
       data = uber.by_day) +
  geom_tile(aes(fill = rides)) +
  scale_fill_gradientn(colors = colorRampPalette(rev(brewer.pal(11, 'RdYlBu')))(100),
                       guide = guide_colorbar(barheight = 20,
                                              title = 'Pickups')) +
  ylab('Date') +
  xlab('Month') +
  ggtitle('Pickups per Date Heatmap') +
  ggsave('graphs/pickups_per_day_heatmap.png')

```


## Pickups per hour by Day Scatterplots

```{r}
# Number of rides per hour scatterplot, color by day, with smooth mean line
ggplot(uber.by_hour,
       aes(x = hour,
           y = rides)) +
  geom_point(aes(color = day),
             position = position_jitter(),
             alpha = .8) +
  geom_smooth() +
  ggtitle('Pickups by Hour and Day') +
  ylab('Number of Pickups') +
  xlab('Time') +
  labs(color = 'Day') +
  scale_x_continuous(breaks = 0:23) +
  scale_color_brewer(type = 'seq',
                     palette = 18) +
  ggsave('graphs/rides_per_hour_color_by_day_scatter.png')

# Number of rides per hour scatterplot with a line for every day (Sun - Sat)
ggplot(uber.by_hour,
       aes(x = hour,
           y = rides)) +
  geom_point(alpha = .2,
             position = position_jitter()) +
  geom_line(aes(color = day),
            stat = 'summary', 
            fun.y = quantile,
            fun.args  =list(probs = .5)) +
  ggtitle('Pickups by Hour and Daily Median') +
  ylab('Number of Pickups') +
  xlab('Time') +
  scale_x_continuous(breaks = 0:23) +
  scale_color_brewer(type = 'seq',
                     palette = 18) +
  ggsave('graphs/rides_per_hour_scatter_with_day_lines.png')


```



-------------- Useless -------------------
## Number of rides by hour, colored by borough, faceted by day

```{r}
ggplot(uber_known.by_hour_borough,
       aes(x = hour,
           y = rides)) +
  geom_point(aes(color = Borough),
             alpha = .5) +
  ggtitle('Pickups by Hour, Borough and Day') +
  xlab('Hour') +
  ylab('Pickups') +
  scale_fill_brewer(type = 'div') +
  facet_wrap(~ day) +
  ggsave('pickups_by_hour_borough_day_scatter.png')
```


# Correlation Tests

```{r}

# Testing corellation by hour and date
with(uber.by_hour, cor.test(hour, rides))
with(uber.by_date, cor.test(date, rides))


```


# Individual Dates

```{r}
# April 25
ggplot(subset(uber, 
              month == 'April'  
              & date == 25),
       aes(x = hour)) +
  geom_freqpoly(binwidth = 1,
                aes(color = day)) +
  scale_x_continuous(breaks = 0:23) +
  scale_color_brewer(type = 'qual', palette = 2) +
  ggtitle('April 25th Pickups') +
  ylab('Number of Pickups')

# May 16
ggplot(subset(uber,
              Month == 'May',
              date == 16),
       aes(x = hour)) +
  geom_freqpoly(binwidth = 1,
                aes(color = day)) +
  scale_x_continuous(breaks = 0:23) +
  scale_color_brewer(type = 'qual', palette = 2) +
  ggtitle('January 13th Pickups') +
  ylab('Number of Pickups')

# June 27 (Missing Data! Where'd midnight - 7am go?)
ggplot(subset(uber_jun, date == 27),
       aes(x = hour)) +
  geom_freqpoly(binwidth = 1,
                aes(color = day)) +
  scale_x_continuous(breaks = 0:23) +
  scale_color_brewer(type = 'qual', palette = 2) +
  ggtitle('June 27th Pickups') +
  ylab('Number of Pickups')

# - Tues, Jan 27 (Lowest Number of Rides)
ggplot(subset(uber_jan, date == 27),
       aes(x = hour)) +
  geom_freqpoly(binwidth = 1,
                aes(color = day)) +
  scale_x_continuous(breaks = 0:23) +
  scale_color_brewer(type = 'qual', palette = 2) +
  ggtitle('January 27th Pickups') +
  ylab('Number of Pickups')
ggsave('jan_27_pickups.png')


```


# Number of rides by date faceted by Month colored by Day

```{r}
# Pickups by date faceted by month
ggplot(uber,
       aes(x = date)) +
  geom_histogram(binwidth = 1,
                aes(fill = day)) +
  scale_x_continuous(breaks = seq(7, 28, 7)) +
  scale_y_continuous(labels = comma) +
  scale_fill_brewer(type = 'seq', palette = 1) +
  ggtitle('Monthly Pickups by Date') +
  xlab('Date') +
  ylab('Number of Pickups') +
  facet_wrap(~ month) +
  ggsave('monthly_pickups_histogram.png')
```


# May and June Close-up (may not use)

```{r}
# May Histogram
ggplot(uber_may,
       aes(x = date)) +
  geom_histogram(binwidth = 1,
                aes(fill = day)) +
  scale_x_continuous(breaks = 1:31) +
  scale_fill_brewer(type = 'seq', palette = 1) +
  ggtitle('May Pickups') +
  ylab('Number of Pickups') +
ggsave('may_pickups_histogram.png')

# June Histogram
ggplot(uber_june,
       aes(x = date)) +
  geom_histogram(binwidth = 1,
                aes(fill = day)) +
  scale_x_continuous(breaks = 1:31) +
  scale_fill_brewer(type = 'seq', palette = 1) +
  ggtitle('June Pickups') +
  ylab('Number of Pickups') +
ggsave('june_pickups_histogram.png')
```



# Create a 3-graph smoothing progression:

```{r}



# By quarter-hour
p1 <- ggplot(uber.by_quarter_hour,
       aes(x = hour_plus_quarter,
           y = rides)) +
  geom_line(color = I('green')) +
  geom_smooth()

# By half hour
p2 <- ggplot(uber.by_half_hour,
       aes(x = hour_plus_half,
           y = rides)) +
  geom_line(alpha = .2)

# By hour
p3 <- ggplot(uber.by_hour,
       aes(x = hour,
           y = rides)) +
  geom_line(alpha = .2)

grid.arrange(p1, p2, p3, ncol = 1)

# Make a histogram! of Manhattan Zone pickups
ggplot(data = subset(uber_jan,
                     Borough == 'Manhattan'),
       aes(x = Zone)) +
  geom_histogram()
```

```{r}
# Scatterplot of pickups per hour in one color plus 3 quartiles
ggplot(uber.by_hour,
       aes(x = hour,
           y = rides)) +
  geom_point(alpha = .2,
             position = position_jitter()) +
  geom_line(stat = 'summary', fun.y = quantile,
            fun.args  =list(probs = .25), 
            color = 'green') +
  geom_line(stat = 'summary', fun.y = quantile,
            fun.args  =list(probs = .5), 
            color = 'blue') +
  geom_line(stat = 'summary', fun.y = quantile,
            fun.args  =list(probs = .95), 
            color = 'purple') +
  #scale_y_log10() +
  ggtitle('Number of Pickups by Hour and Date') +
  ylab('Number of Pickups') +
  xlab('Time') +
  scale_x_continuous(breaks = 0:23) +
  scale_color_brewer(type = 'div')
```


# Density Map with stat_density2d

```{r}
nyc <- get_map("jackson heights, new york", zoom = 11)

nycMap <- ggmap(nyc,
                    extent = "device", 
                    legend = "none")

nycMap +
  stat_density2d(aes(x = lon, 
                     y = lat, 
                     fill = ..level..),
                 alpha = .2,
                 size = .5, 
                 bins = 50, 
                 data = subset(uber_sample, 
                               Borough != 'Unknown'),
                 geom = "polygon",
                 show.legend = F) +
  scale_fill_gradient2(#"Pickups",
                       #limits = c(0, 200),
                       low = "white", 
                       mid = "yellow", 
                       high = "red",
                       guide = 'none') +
  geom_point(aes(x = lon,
                 y = lat,
                 alpha = .05,
                 color = Borough),
             data = subset(uber_sample, 
                               Borough != 'Unknown'))

```

# Using binned location data

```{r}

nyc <- get_map("jackson heights, new york", zoom = 11)
nycMap <- ggmap(nyc,
                    extent = "device")

nycMap +
  geom_point(data = uber_known.by_loc,
             aes(x = lon,
                 y = lat,
                 color = n,
                 size = n/100,
                 alpha = .1)) +
  coord_trans

```



# Experiments Sections:
- Consider turning map scatterplot into map hexplot

```{r}
nycMap +
  coord_cartesian() +
  stat_binhex(data = subset(uber_sample,
                        Borough != 'Unknown'),
                 aes(x = lon,
                     y = lat,
                     alpha = .05))
?stat_density2d
```


```{r}
# NYC Map Scatter plot with density plot (no longer used)
nycMap +
  stat_density2d(aes(x = lon, 
                     y = lat, 
                     fill = ..level..),
                 alpha = .2,
                 bins = 10, 
                 data = subset(uber_sample, 
                               Borough != 'Unknown'),
                 geom = "polygon",
                 show.legend = F) +
  scale_fill_gradient2(#"Pickups",
                       low = "white", 
                       mid = "yellow", 
                       high = "red",
                       limits = c(0, 360),
                       breaks = seq(0, 350, 50)) +
  geom_point(aes(x = lon,
                 y = lat,
                 size = n,
                 color = n,
                 alpha = .01),
             #alpha = .01,
             data = subset(uber_sample_known.by_loc, 
                               Borough != 'Unknown')) +
  scale_color_gradient2(low = 'yellow',
                       high = 'red',
                       mid = 'yellow',
                       guide = guide_colorbar(barheight = 20,
                                              title = 'Pickups')) +
  scale_size(guide = 'none') +
  guides(alpha = F)

```


# Sources of data:

1. Uber: https://github.com/fivethirtyeight/uber-tlc-foil-response
2. ggmap: D. Kahle and H. Wickham. ggmap: Spatial Visualization with ggplot2. 
The R Journal, 5(1), 144-161. URL
  http://journal.r-project.org/archive/2013-1/kahle-wickham.pdf

```{r}
save(taxi_lookup, 
     uber, 
     file = file.path('/Users/courtneyfergusonlee/p4/uber.RData'))
```

